distr <- rbind(1:max(Values), 0)
distr[2,as.numeric(names(table(Values)))] <- table(Values)/length(Values)
distr
plot(distr[1,],distr[2,],type="h")
#Values heeft een te grootte value, die gaat eruit
Values[Values < max(Values)]
#Values heeft een te grootte value, die gaat eruit
Values[Values < max(Values)]
sort(Values)
Values
nValuessort(Values)
nValues <- sort(Values)
nValues
#Values heeft een te grootte value, die gaat eruit
Values[Values < max(Values)]
nValues <- sort(Values)
nValues
#verwerken in nieuwe variabelen
Values <- data_splitser$values
Years <- data_splitser$ind
print(Values)
print(Years)
#Values heeft een te grootte value, die gaat eruit
Values
Values[Values < max(Values)]
#Values heeft een te grootte value, die gaat eruit
Values
#verwerken in nieuwe variabelen
Values <- data_splitser$values
Years <- data_splitser$ind
print(Values)
print(Years)
#Values heeft een te grootte value, die gaat eruit
Values
print(sort(Values))
Values[Values < max(Values)]
print(sort(Values))
nValues <- Values[Values < max(Values)]
print(sort(nValues))
#verwerken in nieuwe variabelen
Values <- data_splitser$values
Years <- data_splitser$ind
print(Values)
print(Years)
#Values heeft een te grootte value, die gaat eruit
nValues <- Values[Values < max(Values)]
distr[2,as.numeric(names(table(nValues)))] <- table(nValues)/length(nValues)
length(nValues)
distr <- rbind(1:max(nValues), 0)
distr[2,as.numeric(names(table(nValues)))] <- table(nValues)/length(nValues)
plot(distr[1,],distr[2,],type="h")
hist(nValues)
hist(nValues, breaks=48)
hist(nValues, breaks=40)
hist(nValues, breaks=10)
hist(nValues, breaks=15)
hist(nValues, breaks=15)
hist(nValues, breaks=20)
hist(nValues, breaks=19)
hist(nValues, breaks=10)
hist(nValues, breaks=20)
hist(nValues, breaks=10)
hist(nValues, breaks=10)
hist(nValues, breaks=20)
hist(nValues, breaks=10)
hist(nValues, breaks=20)
hist(nValues, breaks=10)
hist(nValues, breaks=20)
hist(nValues, breaks=10)
hist(nValues, breaks=20)
hist(nValues, breaks=10)
verLogN <- rlnorm(1000, 1, 100)
hist(verLogN, breaks = 10)
verLogN <- rlnorm(1000, 1, 1)
hist(verLogN, breaks = 10)
hist(verLogN, breaks = 100)
max(verLogN)
sort(verLogN)
verLogN <- rlnorm(1000, 1, 1)
sort(verLogN)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 1, 10)
verLogN <- rlnorm(1000, 1, 10)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 1, 2)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 1, 1)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 10, 1)
hist(verLogN, breaks = 100)
plot(getallenvector)
verLogN <- rlnorm(1000, 10, 1)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, -2, 1)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, -5, 1)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 1000, 1)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 10, 1)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 1, 1)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 0, 0.5)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 0, 20)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 0, 2)
hist(verLogN, breaks = 100)
verLogN <- rlnorm(1000, 0, 0.000001)
hist(verLogN, breaks = 100)
hist(nValues, breaks=10)
hist(nValues, breaks=20)
hist(nValues, breaks=10)
hist(nValues, breaks=10, freq = FALSE)
hist(nValues, breaks=20)
hist(nValues, breaks=10, freq = FALSE)
min(nValues)
plot(distr[1,],distr[2,],type="h")
plot(distr[1,]-59,distr[2,],type="h")
hist(nValues, breaks=10, freq = FALSE)
min(nValues)
hist(nValues - 59, breaks=20)
hist(nValues, breaks=10, freq = FALSE)
hist(nValues - 59, breaks=20)
hist(nValues - 59, breaks=10)
hist(nValues - 59, breaks=20)
hist(nValues - 59, breaks=20, freq = FALSE)
Values
sumVals = sum(Values)
sumVals
gemiddelde = 1/length(Values) * sumVals
gemiddelde
install.packages("extRemes")
library(extRemes)
Values
fit <- fevd(data, type = "Gom")
fit <- fevd(data, type = "GP")
fit <- fevd(Values, type = "GP")
#verwerken in nieuwe variabelen
Values <- data_splitser$values
load("maxrain.Rdata")
#splitst de data in de jaartallen en de waardes:
print(maxrain)
data_splitser <- stack(maxrain)
print(data_splitser)
print(data_splitser)
#verwerken in nieuwe variabelen
Values <- data_splitser$values
Years <- data_splitser$ind
print(Values)
print(Years)
Values
fit <- fevd(Values, type = "GP")
typeof(Values)
fit <- fevd(Values, type = "GP")
is.vector(Values)
Values <- na.omit(Values)
fit <- fevd(Values, type = "GP")
fit <- fevd(Values, type = c("GP"))
fit <- fevd(Values)
fit <- fevd(Values, type = c("Gumbel"))
fit
fit <- fevd(Values, type = c("Gumbel"), method = c("Lmoments"))
fit <- fevd(Values, type = c("GP"), method = c("Lmoments"))
fit <- fevd(Values, type = c("PP"), method = c("Lmoments"))
fit
fit <- fevd(Values, type = c("GEV"), method = c("Lmoments"))
fit
hist(nValues, breaks=10, freq = FALSE)
hist(nValues - 59, breaks=20, freq = FALSE)
hist(nValues, breaks=10, freq = FALSE)
hist(nValues, breaks = 5, freq = FALSE)
hist(nValues, breaks = 60, freq = FALSE)
hist(nValues, breaks = 50, freq = FALSE)
hist(nValues, breaks = 40, freq = FALSE)
hist(nValues, breaks = 30, freq = FALSE)
hist(nValues, breaks=10, freq = FALSE)
hist(rgumbel(116, 114, 46), breaks = 10, freq = FALSE)
install.packages("extraDistr")
hist(rgumbel(116, 114, 46), breaks = 10, freq = FALSE)
library(extraDistr)
hist(rgumbel(116, 114, 46), breaks = 10, freq = FALSE)
hist(rgumbel(116, 114, 46), breaks = 20
hist(rgumbel(116, 114, 46), breaks = 10, freq = FALSE)
hist(nValues - 59, breaks=20, freq = FALSE)
hist(nValues - 59, breaks=15, freq = FALSE)
hist(nValues - 59, breaks=10, freq = FALSE)
hist(rgumbel(116, 114, 46), breaks = 10, freq = FALSE)
hist(rgumbel(116, 114, 46), breaks = 20, freq = FALSE)
hist(rgumbel(116, 114, 46), breaks = 20, freq = FALSE)
hist(rgumbel(1000, 114, 46), breaks = 20, freq = FALSE)
hist(rgumbel(1000, 114, 46), breaks = 20, freq = FALSE)
hist(nValues, breaks=10, freq = FALSE)
#load the data into the program
load("maxrain.Rdata")
#seperate the rain into a parameter years, which we won't use, and values, which we will use
print(maxrain)
data_splitser <- stack(maxrain)
print(data_splitser)
typeof(Values)
typeof(values)
values <- data_splitser$values #extracts the values
years <- data_splitser$ind #extracts the years
typeof(values)
is.vector(values)
Values <- na.omit(Values)
values <- na.omit(values)
print(values)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 50, freq = FALSE)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 40, freq = FALSE)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 30, freq = FALSE)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 30, freq = FALSE)
#load the data into the program
load("maxrain.Rdata")
#seperate the rain into a parameter years, which we won't use, and values, which we will use
data_splitser <- stack(maxrain) #contains seperated data
values <- data_splitser$values #extracts the values
years <- data_splitser$ind #extracts the years
values <- na.omit(values)#finally we omit any incomplete cases, just in case
typeof(values) #values has a "double" type
is.vector(values) #values is indeed a vector, like we want it to be.
#we compute our first histogram to see what the data looks like
hist(values, breaks = 30, freq = FALSE)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 10, freq = FALSE)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 60, freq = FALSE)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 50, freq = FALSE)
print(sortedValues)
sortedValues <- sort(values)
print(sortedValues)
hist(values, breaks = 50, freq = FALSE) #we stay with 50 breaks
hist(nValues, breaks = 50, freq = FALSE) #we stay with 50 breaks
hist(nValues, breaks = 40, freq = FALSE) #we stay with 50 breaks
hist(nValues, breaks = 30, freq = FALSE) #we stay with 50 breaks
hist(nValues, breaks = 30, freq = FALSE) #we stay with 50 breaks
#we compute our first histogram to see what the data looks like
hist(values, breaks = 50, freq = FALSE) #we choose 50 breaks arbitrarily
#we compute our first histogram to see what the data looks like
hist(values, breaks = 30, freq = FALSE) #we choose 50 breaks arbitrarily
#we compute our first histogram to see what the data looks like
hist(values, breaks = 30, freq = FALSE) #we choose 50 breaks arbitrarily
#we compute our first histogram to see what the data looks like
hist(values, breaks = 20, freq = FALSE) #we choose 50 breaks arbitrarily
hist(nValues, breaks = 20, freq = FALSE) #we stay with 50 breaks
hist(nValues, breaks = 30, freq = FALSE) #we stay with 50 breaks
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
dataMean = 1/length(Values) * sumVals
dataMean
#we calculate the mean by summing the values and dividing by the length of our set
sumVals = sum(nValues)
dataMean = 1/length(nValues) * sumVals
print(dataMean)
knitr::opts_chunk$set(echo = TRUE)
library(extRemes)
library(extraDistr)
#load the data into the program
load("maxrain.Rdata")
#seperate the rain into a parameter years, which we won't use, and values, which we will use
data_splitser <- stack(maxrain) #contains seperated data
values <- data_splitser$values #extracts the values
years <- data_splitser$ind #extracts the years
values <- na.omit(values)#finally we omit any incomplete cases, just in case
typeof(values) #values has a "double" type
is.vector(values) #values is indeed a vector, like we want it to be.
#load the data into the program
load("maxrain.Rdata")
#seperate the rain into a parameter years, which we won't use, and values, which we will use
data_splitser <- stack(maxrain) #contains seperated data
values <- data_splitser$values #extracts the values
years <- data_splitser$ind #extracts the years
values <- na.omit(values)#finally we omit any incomplete cases, just in case
typeof(values) #values has a "double" type
is.vector(values) #values is indeed a vector, like we want it to be.
#we compute our first histogram to see what the data looks like
hist(values, breaks = 20, freq = FALSE) #we choose 20 breaks arbitrarily
#sort the values to see how many we need to remove
sortedValues <- sort(values)
print(sortedValues)
#We see one outlier, 441, so we remove it from the data to create a vector new values:
nValues <- Values[values < max(values)]
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
#we calculate the mean by summing the values and dividing by the length of our set
sumVals = sum(nValues)
dataMean = 1/length(nValues) * sumVals
print(dataMean)
rnbinom(1000, 5.3, 0.0346)
hist(rnbinom(1000, 5.3, 0.0346), breaks=30, freq=TRUE)
hist(rnbinom(1000, 5.3, 0.0346), breaks=30, freq=FALSE)
hist(rnbinom(10000, 5.3, 0.0346), breaks=30, freq=FALSE)
plot(rnbinom(10000, 5.3, 0.0346))
load("norain.Rdata")
print(norain)
distr <- rbind(1:30,0)
distr
print(length(norain))
print(table(norain)/length(norain))
distr[2,as.numeric(names(table(norain)))] <- table(norain)/length(norain)
plot(distr[1,],distr[2,],type="h")
plot(distr[1,],distr[2,],type="p")
plot(distr[1,],distr[2,],type="h")
points(1:30,dpois(1:30,11),col="blue",pch=19)
points(1:30,dnbinom(1:30,144/5,12/17),col="red",pch=19)
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
points(1:30,dpois(1:30,11),col="blue",pch=19)
points(1:30,dpois(1:400,11),col="blue",pch=19)
points(1:400,dpois(1:400,11),col="blue",pch=19)
rnbinom(10000, 5.3, 0.0346)
rbind(1:30,0)
length(values) #we later want to know how much data points we have
length(values) #we later want to know how much data points we have
print(norain)
points(1:333,dpois(1:333,11),col="blue",pch=19)
rnbinom(10000, 5.3, 0.0346)
print(distr)
distr <- rbind(1:333)
print(distr)
distr <- rbind(1:333, 0)
print(distr)
table(norain)
table(nValues)
names(table(nValues))
as.numeric(names(table(nValues)))
justValues <- as.numeric(names(table(nValues)))
print(justValues)
distr <- rbind(1:333, 0)
print(distr)
justValues <- as.numeric(names(table(nValues))) #will just contain values, no duplicates
print(justValues)
distr[2, justValues] <- table(nValues)/length(nValues)
print(distr)
plot(distr[1,],distr[2,],type="h")
load("norain.Rdata")
print(norain)
rbind(1:30,0)
distr <- rbind(1:30,0)
distr
print(length(norain))
print(table(norain)/length(norain))
table(norain)
distr[2,as.numeric(names(table(norain)))] <- table(norain)/length(norain)
plot(distr[1,],distr[2,],type="h")
plot(distr[1,],distr[2,],type="h")
distr <- rbind(1:333, 0) #we create a matrix with all the possible values from nValues
justValues <- as.numeric(names(table(nValues))) #will just contain values, no duplicates
distr[2, justValues] <- table(nValues)/length(nValues) #we insert the
plot(distr[1,],distr[2,],type="h")
#load the data into the program
load("maxrain.Rdata")
#seperate the rain into a parameter years, which we won't use, and values, which we will use
data_splitser <- stack(maxrain) #contains seperated data
values <- data_splitser$values #extracts the values
years <- data_splitser$ind #extracts the years
values <- na.omit(values)#finally we omit any incomplete cases, just in case
typeof(values) #values has a "double" type
is.vector(values) #values is indeed a vector, like we want it to be.
length(values) #we later want to know how much data points we have
#we compute our first histogram to see what the data looks like
hist(values, breaks = 20, freq = FALSE) #we choose 20 breaks arbitrarily
#sort the values to see how many we need to remove
sortedValues <- sort(values)
print(sortedValues)
#We see one outlier, 441, so we remove it from the data to create a vector new values:
nValues <- values[values < max(values)]
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
#we calculate the mean by summing the values and dividing by the length of our set
sumVals = sum(nValues)
dataMean = 1/length(nValues) * sumVals
print(dataMean)
distr <- rbind(1:333, 0) #we create a matrix with all the possible values from nValues
justValues <- as.numeric(names(table(nValues))) #will just contain values, no duplicates
distr[2, justValues] <- table(nValues)/length(nValues) #we insert the
plot(distr[1,],distr[2,],type="h")
rnbinom(10000, 5.3, 0.0346)
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
points(1:333,dpois(1:333,11),col="blue",pch=19)
plot(distr[1,],distr[2,],type="h")
distr[1,]
distr[2,]
plot(distr[1,],distr[2,],type="p")
typeof(distr[2,])
distr[2,]
points(1:30,dpois(1:30,11),col="blue",pch=19)
points(1:30,dpois(1:30,11),col="blue",pch=19)
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
points(1:30,dpois(1:30,11),col="blue",pch=19)
?points
points(1:333,dpois(1:333,11),col="blue",pch=19)
plot(distr[1,],distr[2,],type="h")
plot(distr[1,],distr[2,],type="h")
print(norain)
rbind(1:30,0)
distr <- rbind(1:30,0)
distr
print(length(norain))
print(table(norain)/length(norain))
table(norain)
distr[2,as.numeric(names(table(norain)))] <- table(norain)/length(norain)
plot(distr[1,],distr[2,],type="h")
typeof(distr[2,])
distr[2,]
points(1:30,dpois(1:30,11),col="blue",pch=19)
distr <- rbind(1:333, 0) #we create a matrix with all the possible values from nValues
justValues <- as.numeric(names(table(nValues))) #will just contain values, no duplicates
distr[2, justValues] <- table(nValues)/length(nValues) #we insert the
plot(distr[1,],distr[2,],type="p")
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
points(1:500, dnbinom(1:500, 5.3, 0.0364), col="blue", pch=19)
hist(nValues, breaks = 30, freq = FALSE) #we stay with 30 breaks
points(1:500, dnbinom(1:500, 5.3, 0.0364), col="blue", pch=19)
points(1:500, dnbinom(1:500, 5.3, 0.0364), col="blue", pch=15)
points(1:500, dnbinom(1:500, 5.3, 0.0364), col="blue", pch=10)
hist(nValues, breaks = 20, freq = FALSE) #we stay with 30 breaks
points(1:500, dnbinom(1:500, 5.3, 0.0364), col="blue", pch=10)
hist(nValues, breaks = 10, freq = FALSE) #we stay with 30 breaks
points(1:500, dnbinom(1:500, 5.3, 0.0364), col="blue", pch=10)
hist(nValues, breaks = 10, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 5.3, 0.0364), col="blue", pch=10)
points(1:500, dnbinom(1:500, 5, 0.0364), col="blue", pch=10)
hist(nValues, breaks = 10, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 5, 0.0364), col="blue", pch=10)
dnbinom(300, 5, 0.0364)
1-pnbinom(300, 5, 0.0364)
pnbinom(300, 5, 0.0364)
print(1-pnbinom(300, 5, 0.0364))
1-pnbinom(300, 5, 0.0364)
print(
print(1-pnbinom(300, 5, 0.0364))
stop
print(1-pnbinom(300, 5, 0.0364))
vals_over_300 <- sum(values > 300)
vals_over_300
vals_over_300/length(values)
print(emp_value)
emp_value <- vals_over_300/length(values)
print(emp_value)
dataMean = 1/length(nValues) * sumVals
print(dataMean)
dataVar(nValues)
dataVar <- var(nValues)
print(dataVar)
hist(nValues, breaks = 10, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 20, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 50, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 50, freq = TRUE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 50, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 5, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 6, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 7, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 8, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 9, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 10, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
print(dataMean)
print(dataVar)
points(1:500, dnbinom(1:500, 5, 0.0357), col="red", pch=10)
hist(nValues, breaks = 10, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
points(1:500, dnbinom(1:500, 5, 0.0357), col="red", pch=10)
vals_over_300 <- sum(values > 300)
emp_value <- vals_over_300/length(values)
print(emp_value)
print(1-pnbinom(300, 6, 0.0357))
print(1-pnbinom(300, 5, 0.0357))
print(1-pnbinom(300, 6, 0.0357))
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
hist(nValues, breaks = 10, freq = FALSE) #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
print(1-pnbinom(300, 6, 0.0357))
print(emp_value)
vals_over_300 <- sum(values > 300)
emp_value <- vals_over_300/length(values)
print(emp_value)
knitr::opts_chunk$set(echo = TRUE)
print(emp_value_no_outlier)
vals_over_300_no_outlier <- sum(nValues > 300)
emp_value_no_outlier <- vals_over_300_no_outlier/length(nValues)
print(emp_value_no_outlier)
#we compute our first histogram to see what the data looks like
hist(values, breaks = 20, freq = FALSE, main = "Histogram of our values vector"
,xlab = "amount of rain in mm") #we choose 20 breaks arbitrarily
#we choose 10 breaks because it makes a nice shape we can work with
hist(nValues, breaks = 10, freq = FALSE, main = "Histogram of our values vector"
,xlab = "amount of rain in mm")
#we choose 10 breaks because it makes a nice shape we can work with
hist(nValues, breaks = 10, freq = FALSE, main = "Histogram of our nValues vector"
,xlab = "amount of rain in mm")
hist(nValues, breaks = 10, freq = FALSE, main = "Histogram of our nValues vector
with our negative binomial distribution plotted over it"
,xlab = "amount of rain in mm") #our histogram again
points(1:500, dnbinom(1:500, 6, 0.0357), col="blue", pch=10)
#we calculate the empirical probability for rainfall over 300mm
vals_over_300_no_outlier <- sum(nValues > 300)
emp_value_no_outlier <- vals_over_300_no_outlier/length(nValues)
print(emp_value_no_outlier)
